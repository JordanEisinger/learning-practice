{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec**\n",
    "* Words into vectors (aka embeddings) &rarr; Goal is to produce high-quality word embeddings\n",
    "\n",
    "Example:\n",
    "\n",
    "*vec(king)* = [-2.1, 4.1, 0.6] \\\n",
    "*vec(queen)* = [-1.9, 2.6, 1.5] \\\n",
    "*vec(man)* = [3.0, -1.1, -2] \\\n",
    "*vec(woman)* = [2.8, -2.6, -1.1]\n",
    "\n",
    "In terms of Euclidian distance, the word vectors for *king* and *queen* are closer than the ones for *king* and *woman*.\n",
    "* Another metric to measure likeness is *cosine similarity*, which only looks at the angle between two vectors and not their length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dolor', ['Lorem', 'ipsum', 'sit', 'amet,']), ('sit', ['ipsum', 'dolor', 'amet,', 'consectetur'])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "text = \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc eu sem \n",
    "scelerisque, dictum eros aliquam, accumsan quam. Pellentesque tempus, lorem ut \n",
    "semper fermentum, ante turpis accumsan ex, sit amet ultricies tortor erat quis \n",
    "nulla. Nunc consectetur ligula sit amet purus porttitor, vel tempus tortor \n",
    "scelerisque. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices \n",
    "posuere cubilia curae; Quisque suscipit ligula nec faucibus accumsan. Duis \n",
    "vulputate massa sit amet viverra hendrerit. Integer maximus quis sapien id \n",
    "convallis. Donec elementum placerat ex laoreet gravida. Praesent quis enim \n",
    "facilisis, bibendum est nec, pharetra ex. Etiam pharetra congue justo, eget \n",
    "imperdiet diam varius non. Mauris dolor lectus, interdum in laoreet quis, \n",
    "faucibus vitae velit. Donec lacinia dui eget maximus cursus. Class aptent taciti\n",
    "sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Vivamus\n",
    "tincidunt velit eget nisi ornare convallis. Pellentesque habitant morbi \n",
    "tristique senectus et netus et malesuada fames ac turpis egestas. Donec \n",
    "tristique ultrices tortor at accumsan.\n",
    "\"\"\".split()\n",
    "\n",
    "# Create skipgrams\n",
    "skipgrams = []\n",
    "for i in range(CONTEXT_SIZE, len(text) - CONTEXT_SIZE):\n",
    "    array = [text[j] for j in np.arange(i - CONTEXT_SIZE, i + CONTEXT_SIZE + 1) if j != i]\n",
    "    skipgrams.append((text[i], array))\n",
    "\n",
    "print(skipgrams[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary = 121\n"
     ]
    }
   ],
   "source": [
    "vocab = set(text)\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(f\"Length of vocabulary = {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
